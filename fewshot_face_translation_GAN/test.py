# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/shaoanlu/fewshot-face-translation-GAN/blob/master/colab_demo.ipynb

## Colab commands

The following cells will download prerequisite for fewshot-face-translation-GAN.
"""
# Commented out IPython magic to ensure Python compatibility.
# %cd "fewshot-face-translation-GAN"

# Download pre-trined weights
'''
!gdown https://drive.google.com/uc?id=1DUMmZGTGKMyEYSKy-w34IDHawVF24rIs
!gdown https://drive.google.com/uc?id=1xl8cg7xaRnMsyiODcXguJ83d5hwodckB

!mkdir weights
!mv decoder.h5 weights/decoder.h5
!mv encoder.h5 weights/encoder.h5

!ls
'''
"""## Load GAN model"""
import glob
import warnings
from itertools import permutations
from tqdm import tqdm
import random
warnings.filterwarnings("ignore")

from models import FaceTranslationGANInferenceModel

model = FaceTranslationGANInferenceModel()
print("loaded GAN model")

"""## Load face-toolbox"""

from face_toolbox_keras.models.verifier.face_verifier import FaceVerifier
fv = FaceVerifier(classes=512)

from face_toolbox_keras.models.parser import face_parser
fp = face_parser.FaceParser()

from face_toolbox_keras.models.detector import face_detector
fd = face_detector.FaceAlignmentDetector()

from face_toolbox_keras.models.detector.iris_detector import IrisDetector
idet = IrisDetector()
#idet.set_detector(fd)
print("loaded face-toolbox")

"""# Translate faces"""

import numpy as np
from utils import utils
from matplotlib import pyplot as plt
print("translated faces")

"""### Set path to input images"""

image_locations = glob.glob("C:\\Users\\Caspar Chen\\Documents\\GitHub\\adversarial_deepfakes\\img_align_celeba\\*")[756:]

"""### Inferece

It requires additional time to load models for the first infernce.
"""
'''
i = 0
for fn_src, fn_tar in tqdm(permutations(image_locations, 2)):
    i+=1
    try:
        src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)
        tar, emb_tar = utils.get_tar_inputs([fn_tar], fd, fv)
        out = model.inference(src, mask, tar, emb_tar)
        result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))
        plt.imshow(result_face)
        result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)
        plt.imshow(result_img)
        print("got result image")
        # plt.imshow(result_img)
        fn_src_name = (fn_src.split("\\")[-1]).split(".")[0]
        fn_tar_name = (fn_tar.split("\\")[-1]).split(".")[0]
        # plt.savefig('generated_images/{}_{}.jpg'.format(fn_src_name, fn_tar_name))
        plt.imsave('{}_{}.jpg'.format(fn_src_name, fn_tar_name), result_img)
        print("saved",fn_src,"to",fn_tar)
    except: 
        print(fn_src, fn_tar, "****", i , "******")
'''


for i in range(2000):
	try:
		fn_src = image_locations[i]
		fn_tar = random.choice(image_locations)
		while(fn_tar == fn_src):
			fn_tar = random.choice(image_locations)
		src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)
		tar, emb_tar = utils.get_tar_inputs(fn_tar, fd, fv)

		out = model.inference(src, mask, tar, emb_tar)

		result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))

		result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)
		plt.imshow(result_img)
		fn_src_name = (fn_src.split("\\")[-1]).split(".")[0]
		fn_tar_name = (fn_tar.split("\\")[-1]).split(".")[0]
		plt.imsave('{}_{}.jpg'.format(fn_src_name, fn_tar_name), result_img)
		print("written image {}_{}".format(fn_src_name, fn_tar_name))
	except:
		print(fn_src, fn_tar)

'''
fn_src = "caspar.jpg"
fn_tar = "eden.jpg"
src, mask, aligned_im, (x0, y0, x1, y1), landmarks = utils.get_src_inputs(fn_src, fd, fp, idet)
tar, emb_tar = utils.get_tar_inputs(fn_tar, fd, fv)

out = model.inference(src, mask, tar, emb_tar)

result_face = np.squeeze(((out[0] + 1) * 255 / 2).astype(np.uint8))
print("got result face")
#plt.imshow(result_face)
#plt.show()
#result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)
result_img = utils.post_process_result(fn_src, fd, result_face, aligned_im, src, x0, y0, x1, y1, landmarks)
plt.imshow(result_img)
#plt.show()
fn_src_name = (fn_src.split("\\")[-1]).split(".")[0]
fn_tar_name = (fn_tar.split("\\")[-1]).split(".")[0]
plt.imsave('{}_{}.jpg'.format(fn_src_name, fn_tar_name), result_img)
print("written image {}_{}".format(fn_src_name, fn_tar_name))
# plt.savefig('{}_{}.jpg'.format(fn_src_name, fn_tar_name))
'''